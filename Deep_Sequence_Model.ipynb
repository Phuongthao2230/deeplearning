{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[link code gốc](**https**://github.com/abdelghanibelgaid/nnvpp/blob/main/notebook.ipynb)"
      ],
      "metadata": {
        "id": "4ovk8UZYb0Bi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvXhjfD2yfvy"
      },
      "outputs": [],
      "source": [
        "import os, io, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from scipy.fft import fft\n",
        "from scipy.signal import hilbert, blackman\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Dropout\n",
        "from tensorflow.keras.layers import Add, concatenate, Dense, LSTM, GRU, SimpleRNN, RNN, Input, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_columns',None)\n",
        "plt.style.use('fivethirtyeight')\n",
        "import itertools\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from sklearn.model_selection import GroupKFold, train_test_split\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error , r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "gc.enable()\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDTXBmsANenz"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "def seed_everything(seed=SEED):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "494KKhbHPe3H",
        "outputId": "c9a849b9-99db-4d68-f24f-e9c33d643ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Deep Learning đồ án/Ventilator-pressure dataset/data.csv')"
      ],
      "metadata": {
        "id": "ECK4gZdoNvxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.1, random_state=7) \n",
        "test, val = train_test_split(test, test_size=0.5, random_state=7)\n",
        "train=train.iloc[:train.shape[0]//80*80,:]\n",
        "test=test.iloc[:test.shape[0]//80*80,:]\n",
        "val = val.iloc[:val.shape[0]//80*80,:]\n",
        "print(train.shape, test.shape, val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dxgs0BXRQSr",
        "outputId": "e578fdd2-0af1-406b-957c-9a0dee49aacb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(362480, 92) (20080, 92) (20080, 92)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train[['pressure']].to_numpy().reshape(-1, 80)\n",
        "x_train = train.drop(['pressure','id', 'breath_id'], axis=1)\n",
        "y_test = test[['pressure']].to_numpy().reshape(-1, 80)\n",
        "x_test = test.drop(['id', 'breath_id', 'pressure'], axis=1)\n",
        "y_val = val[['pressure']].to_numpy().reshape(-1, 80)\n",
        "x_val = val.drop(['pressure','id', 'breath_id'], axis=1)\n",
        "\n",
        "# scale\n",
        "RS = RobustScaler(quantile_range=(20.0, 80.0))\n",
        "x_train = RS.fit_transform(x_train)\n",
        "x_test = RS.fit_transform(x_test)\n",
        "x_val = RS.fit_transform(x_val)\n",
        "# reshape\n",
        "x_train = x_train.reshape(-1, 80, x_train.shape[-1])\n",
        "x_test = x_test.reshape(-1, 80, x_test.shape[-1])\n",
        "x_val = x_val.reshape(-1, 80, x_val.shape[-1])"
      ],
      "metadata": {
        "id": "RKftdR0ZSGXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[-2:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9gXDmI58jfm",
        "outputId": "d75498e9-a4b7-48e5-8c17-845d8231450f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 89)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.functional import split\n",
        "# datasets.py: Define the data interator (data loader)\n",
        "from scipy.ndimage import convolve1d\n",
        "from scipy.ndimage import convolve1d, gaussian_filter1d\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "from scipy.signal.windows import triang\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "def get_lds_kernel_window(kernel, ks, sigma):\n",
        "    assert kernel in ['gaussian', 'triang', 'laplace']\n",
        "    half_ks = (ks - 1) // 2\n",
        "    if kernel == 'gaussian':\n",
        "        base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks\n",
        "        kernel_window = gaussian_filter1d(base_kernel, sigma=sigma) / max(gaussian_filter1d(base_kernel, sigma=sigma))\n",
        "    elif kernel == 'triang':\n",
        "        kernel_window = triang(ks)\n",
        "    else:\n",
        "        laplace = lambda x: np.exp(-abs(x) / sigma) / (2. * sigma)\n",
        "        kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / max(map(laplace, np.arange(-half_ks, half_ks + 1)))\n",
        "\n",
        "    return kernel_window\n",
        "\n",
        "def GetWeights(labels, reweight='sqrt_inv', max_target=65, lds=True, lds_kernel='gaussian',lds_ks=5,lds_sigma=2):\n",
        "  \n",
        "  value_dict = {x: 0 for x in range(-1,max_target)}\n",
        "  labels = labels.numpy()\n",
        "  labels = np.squeeze(labels.reshape(-1,1))\n",
        "  \n",
        "  #mbr\n",
        "  for label in labels:\n",
        "    value_dict[min(max_target-1, int(label))] += 1\n",
        "  if reweight == 'sqrt_inv':\n",
        "    value_dict = {k: np.sqrt(v) for k, v in value_dict.items()}\n",
        "  elif reweight == 'inverse':\n",
        "    value_dict = {k: np.clip(v, 5, 1000) for k, v in value_dict.items()}\n",
        "  num_per_label = [value_dict[min(max_target-1, int(label))] for label in labels]\n",
        "  if not len(num_per_label) or reweight == 'none':\n",
        "    return None\n",
        "  print(f\"using re-weighting: [{reweight.upper()}]\")\n",
        "  if lds:\n",
        "    lds_kernel_window = get_lds_kernel_window(lds_kernel, lds_ks, lds_sigma)\n",
        "    print(f\"Using LDS: [{lds_kernel.upper()}] ({lds_ks}/{lds_sigma})\")\n",
        "    smoother_value = convolve1d(np.asarray([v for _,v in value_dict.items()]), weights=lds_kernel_window, mode='constant')\n",
        "    num_per_label = [smoother_value[min(max_target-1,int(label))] for label in labels]\n",
        "  \n",
        "  weights = [np.float64(1/x) for x in num_per_label]\n",
        "  scaling = len(weights)/np.sum(weights)\n",
        "  weights = [scaling * x for x in weights]\n",
        "  return tf.convert_to_tensor(np.array(weights))"
      ],
      "metadata": {
        "id": "YhNjpqES9a8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Configuration\n",
        "class CFG:\n",
        "    seed = 42\n",
        "    VERBOSE = 1\n",
        "    random_state = 42\n",
        "    N_FOLDS = 5\n",
        "    EPOCHS = 20\n",
        "    BATCH_SIZE = 128\n",
        "    factor = 0.5# Custom MAE Loss\n",
        "    patience_1 = 5\n",
        "    patience_2 = 15\n",
        "    learning_rate = 1e-3\n",
        "    weight_decay = 1e-3\n",
        "    dropout_rate = 0.2"
      ],
      "metadata": {
        "id": "GXkcr0Kc8nCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accelerator Configuration\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n",
        "    print(\"Running on TPU:\", tpu.master())\n",
        "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "    \n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    BATCH_SIZE = 512\n",
        "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
        "    print(f\"Batch Size: {BATCH_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFiMzf8RJwvo",
        "outputId": "0e53dc1d-041a-4c2b-dea9-69d95f9bcc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on 1 replicas\n",
            "Batch Size: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_mae_loss(y_true, y_pred):\n",
        "  w = GetWeights(y_true)\n",
        "  mae = tf.reshape(w, [-1]) * tf.abs(tf.reshape(y_true, [-1]) - tf.reshape(y_pred, [-1]))\n",
        "  return tf.reduce_sum(mae, axis=-1) #/ tf.reduce_sum(w, axis=-1)"
      ],
      "metadata": {
        "id": "KetKLD3nURs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dnn_model():\n",
        "    x_input = Input(shape=(x_train.shape[-2:]))\n",
        "    \n",
        "    x1 = Bidirectional(LSTM(units=1024, return_sequences=True ))(x_input)\n",
        "    c1 = concatenate([x_input, x1])\n",
        "    \n",
        "    x2 = Dropout(0.1)(c1)\n",
        "    c2 = concatenate([x1, x2])\n",
        "\n",
        "    x3= Bidirectional(LSTM(units=512, return_sequences=True))(c2)\n",
        "    c3 = concatenate([x2, x3])\n",
        "    \n",
        "    x4 = Bidirectional(LSTM(units=256, return_sequences=True))(c3)\n",
        "    c4 = concatenate([x3, x4])\n",
        "\n",
        "    x5 = Dropout(0.2)(c4)\n",
        "    c5 = concatenate([x4, x5])\n",
        "    \n",
        "    x6 = Bidirectional(LSTM(units=128, return_sequences=True))(c5)\n",
        "    c6 = concatenate([x5, x6])\n",
        "\n",
        "    x7 = Dropout(0.1)(c6)\n",
        "    c7 = concatenate([x6, x7])\n",
        "    \n",
        "    x8 = Dense(units=128, activation='selu')(c7)\n",
        "    x_output = Dense(units=1)(x8)\n",
        "    \n",
        "    model = Model(inputs=x_input, outputs=x_output, name='DNN_Model')\n",
        "    model.compile(optimizer='Adam', loss=custom_mae_loss, run_eagerly=True)\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ikBVb75MDS0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = dnn_model()\n",
        "lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=CFG.factor, patience=CFG.patience_1,\n",
        "                               verbose=CFG.VERBOSE)\n",
        "es = EarlyStopping(monitor=\"val_loss\", patience=CFG.patience_2, mode=\"min\",\n",
        "                    restore_best_weights=True, verbose=CFG.VERBOSE)\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=CFG.EPOCHS, batch_size=512,callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFQzT_v7UViV",
        "outputId": "6d712839-723b-4f4f-d1b3-ba7bbedda26a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 1:29 - loss: 683110.5625using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 31s - loss: 545803.0625 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 27s - loss: 564060.4375using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 22s - loss: 507007.9688using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 473900.6875using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 13s - loss: 446304.7500using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 428612.9688 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 409477.5000using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 393106.4375using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 49s 5s/step - loss: 393106.4375 - val_loss: 127078.8828\n",
            "Epoch 2/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 36s - loss: 258236.9219using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 34s - loss: 255298.3438using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 252165.2031using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 247261.8750using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 244303.8438using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 241450.5625using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 238583.7500 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 236485.9219using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 231027.2031using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 231027.2031 - val_loss: 100969.5469\n",
            "Epoch 3/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 35s - loss: 211593.7031using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 208105.1250using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 27s - loss: 204494.0000using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 201757.8125using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 198861.7031using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 13s - loss: 195757.0000using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 193705.7969 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 190915.3125using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 186795.0000using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 43s 5s/step - loss: 186795.0000 - val_loss: 78912.9688\n",
            "Epoch 4/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 38s - loss: 161855.3750using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 33s - loss: 164367.1094using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 162992.2344using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 160058.6250using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 158367.6719using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 156587.3125using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 153794.8750 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 151702.6719using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 148233.5156using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 148233.5156 - val_loss: 61853.5039\n",
            "Epoch 5/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 130537.1172using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 129390.1328using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 27s - loss: 128476.9922using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 22s - loss: 126969.3672using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 124872.0859using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 13s - loss: 123596.0000using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 122486.3047 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 121288.5547using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 118659.3438using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 43s 5s/step - loss: 118659.3438 - val_loss: 53002.6602\n",
            "Epoch 6/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 110247.1562using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 109599.2656using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 108044.4375using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 107815.0703using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 107902.5391using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 107433.4297using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 106495.5625 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 105868.1484using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 104130.3594using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 104130.3594 - val_loss: 47374.5352\n",
            "Epoch 7/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 38s - loss: 97456.7812using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 33s - loss: 97562.5312using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 96810.7500using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 97867.1641using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 97544.8984using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 96621.4297using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 96139.6172 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 95615.3047using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 93924.0859using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 93924.0859 - val_loss: 42735.6016\n",
            "Epoch 8/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 88065.8984using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 88564.3906using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 88871.1875using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 89751.6562using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 90166.3594using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 89731.4922using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 89004.2969 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 88419.7188using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 86945.6406using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 86945.6406 - val_loss: 40001.1758\n",
            "Epoch 9/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 81675.1250using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 81958.3828using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 82434.0312using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 82664.9531using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 83083.0703using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 82920.1953using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 82496.3672 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 82019.7734using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 80352.6641using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 80352.6641 - val_loss: 37591.0273\n",
            "Epoch 10/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 39s - loss: 79831.1250using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 36s - loss: 78397.3438using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 30s - loss: 77397.0000using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 24s - loss: 77226.1250using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 76838.2812using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 15s - loss: 76415.2422using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 10s - loss: 75992.1719using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 5s - loss: 75647.0312 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 74511.2656using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 46s 5s/step - loss: 74511.2656 - val_loss: 35947.0820\n",
            "Epoch 11/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 76860.6562using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 33s - loss: 78031.5078using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 79682.9141using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 79858.6328using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 79400.9844using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 78118.8906using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 77819.6797 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 77808.9453using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 76280.9609using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 76280.9609 - val_loss: 34906.2852\n",
            "Epoch 12/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 39s - loss: 72058.1406using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 33s - loss: 76250.1953using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 74421.7422using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 73386.1406using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 73515.7109using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 72704.6094using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 72345.9922 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 72182.6875using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 70777.9375using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 70777.9375 - val_loss: 33356.2305\n",
            "Epoch 13/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 69382.7031using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 68447.3281using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 27s - loss: 67722.5938using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 67358.8516using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 67094.6406using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 66696.3281using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 66713.0703 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 66577.0938using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 65418.3945using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 65418.3945 - val_loss: 30783.6211\n",
            "Epoch 14/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 40s - loss: 64448.1602using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 34s - loss: 65298.0156using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 29s - loss: 64712.4531using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 24s - loss: 64682.3281using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 64218.2266using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 64103.0508using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 64066.6602 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 64125.3594using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 63297.8633using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 46s 5s/step - loss: 63297.8633 - val_loss: 29373.6309\n",
            "Epoch 15/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 62595.7852using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 62256.5898using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 62573.7656using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 63286.7539using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 63531.8750using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 63304.1836using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 62912.7148 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 62673.8984using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 61801.5273using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 61801.5273 - val_loss: 28871.7441\n",
            "Epoch 16/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 60113.1328using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 33s - loss: 60043.2969using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 59858.5977using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 24s - loss: 59870.6172using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 59878.2266using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 59648.3320using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 59693.4297 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 59957.9570using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 59214.9961using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 59214.9961 - val_loss: 27912.2227\n",
            "Epoch 17/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 39s - loss: 59064.6094using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 34s - loss: 58901.2383using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 29s - loss: 60158.8594using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 24s - loss: 60628.9258using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 60493.3203using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 60197.2656using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 59890.0742 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 59653.7305using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 58659.2930using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 58659.2930 - val_loss: 27727.1680\n",
            "Epoch 18/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 38s - loss: 57030.3945using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 33s - loss: 57164.7266using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 29s - loss: 57904.4414using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 24s - loss: 58710.9336using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 59232.8125using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 59155.9414using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 58869.1680 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 58794.0703using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 57905.8398using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 57905.8398 - val_loss: 27823.4180\n",
            "Epoch 19/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 37s - loss: 57240.3555using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 32s - loss: 56964.8984using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 28s - loss: 56505.8281using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 23s - loss: 56562.9453using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 18s - loss: 57222.8750using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 57473.7461using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 57436.5898 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 57226.7969using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 56241.5117using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 44s 5s/step - loss: 56241.5117 - val_loss: 27936.1797\n",
            "Epoch 20/20\n",
            "using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "1/9 [==>...........................] - ETA: 38s - loss: 57532.6445using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "2/9 [=====>........................] - ETA: 34s - loss: 56688.7734using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "3/9 [=========>....................] - ETA: 29s - loss: 56056.1406using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "4/9 [============>.................] - ETA: 24s - loss: 55608.1367using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "5/9 [===============>..............] - ETA: 19s - loss: 55263.0430using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "6/9 [===================>..........] - ETA: 14s - loss: 55098.4102using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "7/9 [======================>.......] - ETA: 9s - loss: 54917.6602 using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "8/9 [=========================>....] - ETA: 4s - loss: 54854.3281using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - ETA: 0s - loss: 53980.6484using re-weighting: [SQRT_INV]\n",
            "Using LDS: [GAUSSIAN] (5/2)\n",
            "9/9 [==============================] - 45s 5s/step - loss: 53980.6484 - val_loss: 25821.7539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Deep Learning đồ án/model/F0_LDS.h5')"
      ],
      "metadata": {
        "id": "8nCTTmVxZsU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mae_loss(y_true, y_pred):\n",
        "  mae = tf.abs(tf.reshape(y_true, [-1]) - tf.reshape(y_pred, [-1]))\n",
        "  return tf.reduce_sum(mae, axis=-1)"
      ],
      "metadata": {
        "id": "zU4eOETrtHuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dnn_model():\n",
        "    x_input = Input(shape=(x_train.shape[-2:]))\n",
        "    \n",
        "    x1 = Bidirectional(LSTM(units=1024, return_sequences=True ))(x_input)\n",
        "    c1 = concatenate([x_input, x1])\n",
        "    \n",
        "    x2 = Dropout(0.1)(c1)\n",
        "    c2 = concatenate([x1, x2])\n",
        "\n",
        "    x3= Bidirectional(LSTM(units=512, return_sequences=True))(c2)\n",
        "    c3 = concatenate([x2, x3])\n",
        "    \n",
        "    x4 = Bidirectional(LSTM(units=256, return_sequences=True))(c3)\n",
        "    c4 = concatenate([x3, x4])\n",
        "\n",
        "    x5 = Dropout(0.2)(c4)\n",
        "    c5 = concatenate([x4, x5])\n",
        "    \n",
        "    x6 = Bidirectional(LSTM(units=128, return_sequences=True))(c5)\n",
        "    c6 = concatenate([x5, x6])\n",
        "\n",
        "    x7 = Dropout(0.1)(c6)\n",
        "    c7 = concatenate([x6, x7])\n",
        "    \n",
        "    x8 = Dense(units=128, activation='selu')(c7)\n",
        "    x_output = Dense(units=1)(x8)\n",
        "    \n",
        "    model = Model(inputs=x_input, outputs=x_output, name='DNN_Model')\n",
        "    model.compile(optimizer='Adam', loss=\"mean_absolute_error\", run_eagerly=True)\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hNhW2uts3K4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = dnn_model()\n",
        "lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=CFG.factor, patience=CFG.patience_1,\n",
        "                               verbose=CFG.VERBOSE)\n",
        "es = EarlyStopping(monitor=\"val_loss\", patience=CFG.patience_2, mode=\"min\",\n",
        "                    restore_best_weights=True, verbose=CFG.VERBOSE)\n",
        "history = model1.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=CFG.EPOCHS, batch_size=128,callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ed868d-a1f9-415a-a9ed-39a447aea9b7",
        "id": "srVYN1m_3Ug5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "36/36 [==============================] - 30s 701ms/step - loss: 4.1944 - val_loss: 2.4894\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 26s 717ms/step - loss: 2.0055 - val_loss: 1.4826\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 26s 733ms/step - loss: 1.4269 - val_loss: 1.2119\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 27s 752ms/step - loss: 1.2095 - val_loss: 1.0627\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 27s 756ms/step - loss: 1.0841 - val_loss: 0.9814\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 28s 767ms/step - loss: 1.0022 - val_loss: 0.9224\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 28s 778ms/step - loss: 0.9437 - val_loss: 0.8668\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 28s 777ms/step - loss: 0.9042 - val_loss: 0.8596\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 28s 777ms/step - loss: 0.8679 - val_loss: 0.8179\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 28s 780ms/step - loss: 0.8595 - val_loss: 0.7887\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 28s 787ms/step - loss: 0.8111 - val_loss: 0.7762\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 28s 787ms/step - loss: 0.7818 - val_loss: 0.8125\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 28s 790ms/step - loss: 0.7666 - val_loss: 0.7148\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 28s 790ms/step - loss: 0.7465 - val_loss: 0.7194\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 28s 792ms/step - loss: 0.7290 - val_loss: 0.7437\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 29s 797ms/step - loss: 0.7028 - val_loss: 0.6815\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 29s 796ms/step - loss: 0.6804 - val_loss: 0.6720\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 29s 796ms/step - loss: 0.6596 - val_loss: 0.6617\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 29s 803ms/step - loss: 0.6504 - val_loss: 0.6433\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 29s 796ms/step - loss: 0.6297 - val_loss: 0.6619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/drive/MyDrive/Deep Learning đồ án/model/F0.h5')"
      ],
      "metadata": {
        "id": "sIpU6OrmvJal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Kj8Xu1hBM6B",
        "outputId": "d9e8039a-5b4b-44ce-e115-3f6f4c0fb09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 90ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r2_score(y_test, np.squeeze(y_pred)))\n",
        "print(mean_absolute_error(y_test,np.squeeze(y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX5TMxUpBUku",
        "outputId": "2d1fb3dd-7d24-471a-9eee-16bdfc041cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9811113908674489\n",
            "0.6601601163608335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsXSVVfStUxS"
      },
      "outputs": [],
      "source": [
        "def short_metrics(preds, labels, train_labels, many_shot_thr=50000, low_shot_thr=1000):\n",
        "  train_class_count, test_class_count = [], []\n",
        "  mse_per_class, l1_per_class, r2_per_class = [], [], []\n",
        "  for l in np.unique(np.floor(labels)):\n",
        "    train_class_count.append(len(train_labels[np.floor(train_labels)==l]))\n",
        "    test_class_count.append(len(labels[np.floor(labels)==l]))\n",
        "    mse_per_class.append(np.sum((preds[np.floor(labels)==l]-labels[np.floor(labels)==l])**2))\n",
        "    l1_per_class.append(np.sum(np.abs(preds[np.floor(labels)==l]-labels[np.floor(labels)==l])))\n",
        "    r2_per_class.append(r2_score(labels[np.floor(labels)==l],preds[np.floor(labels)==l]))\n",
        "\n",
        "  many_shot_mse, median_shot_mse, low_shot_mse = [], [], []\n",
        "  many_shot_l1, median_shot_l1, low_shot_l1 = [], [], []\n",
        "  many_shot_r2, median_shot_r2, low_shot_r2 = [], [], []\n",
        "  many_shot_cnt, median_shot_cnt, low_shot_cnt = [], [], []\n",
        "  for i in range(len(train_class_count)):\n",
        "      if train_class_count[i] > many_shot_thr:\n",
        "          many_shot_mse.append(mse_per_class[i])\n",
        "          many_shot_l1.append(l1_per_class[i])\n",
        "          many_shot_r2.append(r2_per_class[i])\n",
        "          many_shot_cnt.append(test_class_count[i])\n",
        "      elif train_class_count[i] < low_shot_thr:\n",
        "          low_shot_mse.append(mse_per_class[i])\n",
        "          low_shot_l1.append(l1_per_class[i])\n",
        "          low_shot_r2.append(r2_per_class[i])\n",
        "          low_shot_cnt.append(test_class_count[i])\n",
        "      else:\n",
        "          median_shot_mse.append(mse_per_class[i])\n",
        "          median_shot_l1.append(l1_per_class[i])\n",
        "          median_shot_r2.append(r2_per_class[i])\n",
        "          median_shot_cnt.append(test_class_count[i])\n",
        "\n",
        "  shot_dict = {}\n",
        "  shot_dict['many mse'] = np.sum(many_shot_mse) / np.sum(many_shot_cnt)\n",
        "  shot_dict['many l1'] = np.sum(many_shot_l1) / np.sum(many_shot_cnt)\n",
        "  shot_dict['many r2'] = np.sum(many_shot_r2) / np.sum(many_shot_cnt)\n",
        "  shot_dict['median mse'] = np.sum(median_shot_mse) / np.sum(median_shot_cnt)\n",
        "  shot_dict['median l1'] = np.sum(median_shot_l1) / np.sum(median_shot_cnt)\n",
        "  shot_dict['median r2'] = np.sum(median_shot_r2) / np.sum(median_shot_cnt)\n",
        "  shot_dict['low mse'] = np.sum(low_shot_mse) / np.sum(low_shot_cnt)\n",
        "  shot_dict['low l1'] = np.sum(low_shot_l1) / np.sum(low_shot_cnt)\n",
        "  shot_dict['low r2'] = np.sum(low_shot_r2) / np.sum(low_shot_cnt)\n",
        "\n",
        "  mse = mean_squared_error(preds, labels)\n",
        "  mae = mean_absolute_error(preds, labels)\n",
        "  r2 = r2_score(labels, preds)\n",
        "  print(f\" * Overall: MSE {mse:.3f}\\tL1 {mae:.3f}\\tR2 {r2:.3f}\")\n",
        "  print(f\" * Many: MSE {shot_dict['many mse']:.3f}\\t\"\n",
        "              f\"L1 {shot_dict['many l1']:.3f}\\tR2 score {shot_dict['many r2']:.3f}\")\n",
        "  print(f\" * Median: MSE {shot_dict['median mse']:.3f}\\t\"\n",
        "              f\"L1 {shot_dict['median l1']:.3f}\\tR2 score {shot_dict['median r2']:.3f}\")\n",
        "  print(f\" * Low: MSE {shot_dict['low mse']:.3f}\\t\"\n",
        "              f\"L1 {shot_dict['low l1']:.3f}\\tR2 score {shot_dict['low r2']:.3f}\")\n",
        "\n",
        "  return shot_dict\n",
        "\n",
        "# shot_dict = short_metrics(y_pred.reshape(-1), y_test.reshape(-1), y_train.reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(np.floor(y_train), return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMPeQOWnEQJ_",
        "outputId": "6f6c062f-94f1-4f7a-c411-5ad2165cceaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-2., -1.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,\n",
              "        11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.,\n",
              "        24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.,\n",
              "        37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.,\n",
              "        50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62.,\n",
              "        63., 64.]),\n",
              " array([   144,     11,     66,    245,    385,   2871,   9891,  40277,\n",
              "        123579,  38010,  14378,  12912,  10554,   7083,   6581,   6763,\n",
              "          7060,   6410,   5132,   5048,   4634,   5256,   5353,   4098,\n",
              "          3974,   3603,   4175,   4444,   3405,   2889,   2816,   3135,\n",
              "          3162,   2455,   1730,   1590,   1691,   1834,    954,    658,\n",
              "           470,    438,    426,    315,    221,    186,    176,    170,\n",
              "           127,    117,     68,     61,     64,     49,     35,     52,\n",
              "            32,     31,     23,     17,     20,     18,     13,     12,\n",
              "            12,      8,     63]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/Deep Learning đồ án/model/F0_LDS.h5')\n",
        "y_pred = model.predict(x_test)\n",
        "shot_dict = short_metrics(y_pred.reshape(-1), y_test.reshape(-1), y_train.reshape(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "5u-Z4R6LE90H",
        "outputId": "f9a82d0a-98e6-47ed-befb-f435e8b967f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-efa849bcb93e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Deep Learning đồ án/model/F0_LDS.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshot_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshort_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    707\u001b[0m       \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    710\u001b[0m             \u001b[0;34mf'Unknown {printable_module_name}: {object_name}. Please ensure '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;34m'this object is passed to the `custom_objects` argument. See '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown loss function: custom_mae_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Result of plain model\n",
        "shot_dict = short_metrics(y_pred.reshape(-1), y_test.reshape(-1), y_train.reshape(-1))"
      ],
      "metadata": {
        "id": "K5Cltc4wCaDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327905f6-8aa6-4a82-f7c1-91752b840880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Overall: MSE 1.253\tL1 0.660\tR2 0.981\n",
            " * Many: MSE 0.111\tL1 0.243\tR2 score -0.000\n",
            " * Median: MSE 1.751\tL1 0.854\tR2 score -0.091\n",
            " * Low: MSE 5.948\tL1 1.891\tR2 score nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LDS model\n",
        "# y_pred = model.predict(x_test)\n",
        "shot_dict = short_metrics(y_pred.reshape(-1), y_test.reshape(-1), y_train.reshape(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9iNXiyuVhr3",
        "outputId": "ae41a383-77eb-44ec-9dd8-26f078bd4145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Overall: MSE 2.504\tL1 0.942\tR2 0.963\n",
            " * Many: MSE 0.301\tL1 0.351\tR2 score -0.001\n",
            " * Median: MSE 3.539\tL1 1.229\tR2 score -0.190\n",
            " * Low: MSE 8.579\tL1 2.204\tR2 score nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plain model\n",
        "print(r2_score(y_test, np.squeeze(y_pred)))\n",
        "print(mean_absolute_error(y_test,np.squeeze(y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X37KgO-GPFfB",
        "outputId": "ac97d986-c36b-4cda-aa93-bd5dfe4cef4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9811113908674489\n",
            "0.6601601163608335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = tf.keras.losses.MeanAbsoluteError(\n",
        "    reduction=tf.keras.losses.Reduction.SUM)\n",
        "mae(y_pred.reshape(-1), y_test.reshape(-1)).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoO-i2cRAZyl",
        "outputId": "9dd2361d-dc90-42ae-e565-9ad62568fd28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9584600232089502"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/Deep Learning đồ án/model/weights_F0_LDS\")\n",
        "# load_status = model.load_weights(\"weights_F0_LDS\")"
      ],
      "metadata": {
        "id": "TL0P7XM3BZ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = dnn_model()\n",
        "load_status = model.load_weights(\"/content/drive/MyDrive/Deep Learning đồ án/model/weights_F0_LDS\")"
      ],
      "metadata": {
        "id": "mbbj275QPRW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using DenseWeight"
      ],
      "metadata": {
        "id": "WFw9WkVBfBgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install denseweight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J91nYgqdfE5l",
        "outputId": "92fa2ca2-95b3-4a0f-8101-fa3372a38700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: denseweight in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from denseweight) (1.0.2)\n",
            "Requirement already satisfied: KDEpy in /usr/local/lib/python3.8/dist-packages (from denseweight) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from denseweight) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from KDEpy->denseweight) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from KDEpy->denseweight) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->denseweight) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->denseweight) (3.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.0->KDEpy->denseweight) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.0->KDEpy->denseweight) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.0->KDEpy->denseweight) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.0->KDEpy->denseweight) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2.0->KDEpy->denseweight) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from denseweight import DenseWeight\n",
        "def weight_mae_loss(y_true, y_pred):\n",
        "  # y_true=tf.reshape(y_true, [-1])\n",
        "  dw = DenseWeight(alpha=2)\n",
        "  w = dw.fit(y_true.numpy().reshape(-1))\n",
        "  tf.convert_to_tensor(w)\n",
        "  mae = tf.reshape(w, [-1]) * tf.abs(tf.reshape(y_true, [-1]) - tf.reshape(y_pred, [-1]))\n",
        "  return tf.reduce_sum(mae, axis=-1) #/ tf.reduce_sum(w, axis=-1)"
      ],
      "metadata": {
        "id": "leAUr3Xzf5-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dnn_model():\n",
        "    x_input = Input(shape=(x_train.shape[-2:]), dtype='float32')\n",
        "    \n",
        "    x1 = Bidirectional(LSTM(units=1024, return_sequences=True))(x_input)\n",
        "    c1 = concatenate([x_input, x1])\n",
        "    \n",
        "    x2 = Dropout(0.1)(c1)\n",
        "    c2 = concatenate([x1, x2])\n",
        "\n",
        "    x3= Bidirectional(LSTM(units=512, return_sequences=True))(c2)\n",
        "    c3 = concatenate([x2, x3])\n",
        "    \n",
        "    x4 = Bidirectional(LSTM(units=256, return_sequences=True))(c3)\n",
        "    c4 = concatenate([x3, x4])\n",
        "\n",
        "    x5 = Dropout(0.2)(c4)\n",
        "    c5 = concatenate([x4, x5])\n",
        "    \n",
        "    x6 = Bidirectional(LSTM(units=128, return_sequences=True))(c5)\n",
        "    c6 = concatenate([x5, x6])\n",
        "\n",
        "    x7 = Dropout(0.1)(c6)\n",
        "    c7 = concatenate([x6, x7])\n",
        "    \n",
        "    x8 = Dense(units=128, activation='selu', )(c7)\n",
        "    x_output = Dense(units=1)(x8)\n",
        "    \n",
        "    model = Model(inputs=x_input, outputs=x_output, name='DNN_Model')\n",
        "    model.compile(optimizer='Adam', loss=weight_mae_loss, run_eagerly=True)\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "FlbBky2Boe9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.dtype"
      ],
      "metadata": {
        "id": "HSlRyY1Kg5wJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c939c9-4c7b-4ec0-946d-bad4b86a64fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = dnn_model()\n",
        "lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=CFG.factor, patience=CFG.patience_1,\n",
        "                               verbose=CFG.VERBOSE)\n",
        "es = EarlyStopping(monitor=\"val_loss\", patience=CFG.patience_2, mode=\"min\",\n",
        "                    restore_best_weights=True, verbose=CFG.VERBOSE)\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=CFG.EPOCHS, batch_size=512,callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "8adaae24-fcd7-4616-85e5-4766d280ceeb",
        "id": "_DfTfa9xooRN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-490afa212cfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m es = EarlyStopping(monitor=\"val_loss\", patience=CFG.patience_2, mode=\"min\",\n\u001b[1;32m      5\u001b[0m                     restore_best_weights=True, verbose=CFG.VERBOSE)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'forward_lstm_4' (type LSTM).\n\n{{function_node __wrapped__CudnnRNN_device_/job:localhost/replica:0/task:0/device:GPU:0}} Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 89, 1024, 1, 80, 512, 1024]  [Op:CudnnRNN]\n\nCall arguments received by layer 'forward_lstm_4' (type LSTM):\n  • inputs=tf.Tensor(shape=(512, 80, 89), dtype=float32)\n  • mask=None\n  • training=True\n  • initial_state=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "shot_dict = short_metrics(y_pred.reshape(-1), y_test.reshape(-1), y_train.reshape(-1))"
      ],
      "metadata": {
        "id": "t5m-65ogglbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc37ac67-1e00-4cf8-aa7e-875d59eb4b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 98ms/step\n",
            " * Overall: MSE 2.569\tL1 1.002\tR2 0.962\n",
            " * Many: MSE 0.559\tL1 0.600\tR2 score -0.001\n",
            " * Median: MSE 3.222\tL1 1.160\tR2 score -0.182\n",
            " * Low: MSE 19.716\tL1 3.345\tR2 score nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from scipy.ndimage import convolve1d\n",
        "from utils import get_lds_kernel_window\n",
        "\n",
        "# preds, labels: [Ns,], \"Ns\" is the number of total samples\n",
        "preds, labels = ..., ...\n",
        "# assign each label to its corresponding bin (start from 0)\n",
        "# with your defined get_bin_idx(), return bin_index_per_label: [Ns,] \n",
        "bin_index_per_label = [get_bin_idx(label) for label in labels]\n",
        "\n",
        "# calculate empirical (original) label distribution: [Nb,]\n",
        "# \"Nb\" is the number of bins\n",
        "Nb = max(bin_index_per_label) + 1\n",
        "num_samples_of_bins = dict(Counter(bin_index_per_label))\n",
        "emp_label_dist = [num_samples_of_bins.get(i, 0) for i in range(Nb)]\n",
        "\n",
        "# lds_kernel_window: [ks,], here for example, we use gaussian, ks=5, sigma=2\n",
        "lds_kernel_window = get_lds_kernel_window(kernel='gaussian', ks=5, sigma=2)\n",
        "# calculate effective label distribution: [Nb,]\n",
        "eff_label_dist = convolve1d(np.array(emp_label_dist), weights=lds_kernel_window, mode='constant')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxQnog3um76n",
        "outputId": "6673a3a9-dd3e-4628-e9f4-8a1a1b3aabd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.00017848, 1.00051904, 0.99963178, ..., 0.99962069, 0.99959788,\n",
              "       0.99978285])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from loss import weighted_mse_loss\n",
        "\n",
        "# Use re-weighting based on effective label distribution, sample-wise weights: [Ns,]\n",
        "eff_num_per_label = [eff_label_dist[bin_idx] for bin_idx in bin_index_per_label]\n",
        "weights = [np.float32(1 / x) for x in eff_num_per_label]\n",
        "\n",
        "# calculate loss\n",
        "loss = weighted_mse_loss(preds, labels, weights=weights)"
      ],
      "metadata": {
        "id": "9ACAlwKXYImi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = args.bucket_num\n",
        "        value_lst, bins_edges = np.histogram(targs, bins=bins, range=(0., 5.))"
      ],
      "metadata": {
        "id": "u5AtuCWC2GNl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}